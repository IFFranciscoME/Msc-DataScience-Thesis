# -- Check for the presence of the simpson paradox 
# -- Simpson's paradox is one of many reasons why itâ€™s important to evaluate your models on different slices of data.
# -- Model 1 outperforms model 2 on group A and group B separately, but model 2 can still outperform model 1 overall.

# -- Usefull Difference between AUC & ACC
# -- ------------------------------------------------------------- ------------------------------------- -- #

https://datascience.stackexchange.com/questions/806/advantages-of-auc-vs-standard-accuracy
http://notmatthancock.github.io/2015/11/11/auc-and-accuracy.html

# -- T-FOLD PROCESS
# -- ------------------------------------------------------------- ------------------------------------- -- #
# -- With each T-Fold
# -- -- Separate data in 80% (in sample) - 20% (out of sample)
# -- -- Scale data with a Standarization process (with in sample and out of sample data)
# -- -- Create Autoregressive and Hadamard features (with in sample and out of sample data)
# -- -- Create Symbolic Features (genetic programming) (with in sample and out of sample data)
# -- -- Conduct the hyperparameter optimization for all models (genetic algorithms)
# -- -- -- train with in sample and fitness with tp+tn/total
# -- -- Save the HoF with best N individuals (parameter set)
# -- -- Save the parameter set that produces the max, min value of the fitness metric
# -- -- Calculate model metrics for the entire Hall of Fame
# -- -- -- metrics: AUC and ACC

# -- (Pending) For every model, save the mode parameter set among all the T-Folds
# -- (Pending) add other t-fold sizes (bi-anual, 80-20)

# -- LOCAL EVALUATION
# -- ------------------------------------------------------------- ------------------------------------- -- #
# -- search for the max, min, mode (pending) cases among all the folds
# -- -- display metrics
# -- -- display plots

# -- GLOBAL EVALUATION
# -- ------------------------------------------------------------- ------------------------------------- -- #
# -- with min, max, mode (pending) cases found, evaluate with the rest of T-Folds data
# -- -- display metrics
# -- -- display plots

# -- LOCAL-GLOBAL COMPARISSON
# -- ------------------------------------------------------------- ------------------------------------- -- #
# -- -- DATA ANALYSIS
# -- -- -- Amount/dates of data
# -- -- -- Balance of the clases

# -- -- MODEL ANALYSIS
# -- -- -- change in accuracy
# -- -- -- change in auc

# -- -- FEATURE ANALYSIS
# -- -- -- correlation matrix among features
# -- -- -- outliers presence in features
# -- -- -- Features parsimony (length and depth of program)

# -- PARAMETER ESTABILITY
# -- -- for every model in every T-Fold evaluate the best and worst of the HoF of the fold
# -- -- display timeseries parameters dataframe (parameters of all bests/worsts of all the folds)
# -- -- display timeseries metrics plots (of all bests/worsts of all the folds)
# -- -- -- AUC, ACC
# -- -- display all the ROC curves and average ROC curve plot for every model

# -- Possible questions to answer:
# -- -- is this method useful to find a parameter set that does not change a lot in time ?
# -- -- is this method useful to have a stable generalization error of the model ?
# -- -- does this method shows that a linear combination of non-linear features performs well in financial timeseries forecasting ?
# -- -- what role plays the feature complexity in this method ?
# -- -- What is the time complexity of this method ? 
# -- -- What is the memory complexity of this method ? 
