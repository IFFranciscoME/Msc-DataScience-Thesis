
# -- -------------------------------------------------------------------------- QUESTIONS AND REFERENCES -- # 
# -- --------------------------------------------------------------------------------------------------- -- #

# -- types of normalization scores
https://en.wikipedia.org/wiki/Normalization_(statistics)

# -- AUC vs Logloss as cost functions, which is better for binary classification
Whereas the AUC is computed with regards to binary classification with a varying decision threshold,
logloss actually takes "certainty" of classification into account.

Therefore to my understanding, logloss conceptually goes beyond AUC and is especially relevant in cases
with imbalanced data or in case of unequally distributed error cost 
(for example detection of a deadly disease).

https://stats.stackexchange.com/questions/322408/logloss-vs-gini-auc
https://stats.stackexchange.com/questions/235089/optimizing-auc-vs-logloss-in-binary-classification-
problems

# -- Usefull Difference between AUC & ACC
https://datascience.stackexchange.com/questions/806/advantages-of-auc-vs-standard-accuracy
http://notmatthancock.github.io/2015/11/11/auc-and-accuracy.html

# -- Akaike Criteria
In order to compare between models and between different parameter configurations of the same model

# -- Simpson paradox 
Simpson's paradox is one of many reasons why it’s important to evaluate your models on different slices 
of data. Model 1 outperforms Model 2 on group A and group B separately, but model 2 can still 
outperform model 1 with the overall data.

https://en.wikipedia.org/wiki/Simpson%27s_paradox
Here is a multivariable procedure that explicitly maximizes classification accuracy and prevents
paradoxical confounding. [5, 6]
https://www.researchgate.net/post/How_do_you_explain_higher_discrimination_using_a_SVM_score_
index_unsupervised_from_a_supervised_SVM_model_using_same_dataset

# -- How does batch size affect convergence of SGD and why
https://stats.stackexchange.com/questions/316464/how-does-batch-size-affect-convergence-of-sgd-and-why

# -- How to Control the Stability of Training Neural Networks With the Batch Size
https://machinelearningmastery.com/how-to-control-the-speed-and-stability-of-training-neural-networks
-with-gradient-descent-batch-size/

# -- Number of hidden layers / number of neurons & Universal Aproximation Theorem.
https://www.researchgate.net/post/How-to-decide-the-number-of-hidden-layers-and-nodes-in-a-hidden-layer
https://www.heatonresearch.com/2017/06/01/hidden-layers.html
https://en.wikipedia.org/wiki/Universal_approximation_theorem
https://stats.stackexchange.com/questions/181/how-to-choose-the-number-of-hidden-layers-and-nodes-
in-a-feedforward-neural-netw

# -- RandomForest
https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html

# -- ------------------------------------------------------------------------------------ T-FOLD PROCESS -- # 
# -- --------------------------------------------------------------------------------------------------- -- #

# -- Define T-Fold longitudes: Quarter, Semester, Year, Bi-year, 80-20

# -- Within each T-Fold
# -- -- Separate data in 80% (in sample) - 20% (out of sample)

# -- -- (OPTION 1) From the begining Scale data with 3 options
# -- -- -- (OPTION 1) Normlize x/max(x)
# -- -- -- (OPTION 2) Standarize (x-mean(x))/sd(x)
# -- -- -- (OPTION 3) Robust Scale (x - median(x))/IQR

# -- -- -- Create Autoregressive and Hadamard features
# -- -- -- Create Symbolic Features (genetic programming)
# -- -- Continue

# -- -- (OPTION 2) After generating Symbolic Features Scale all the data with 3 options
# -- -- -- (OPTION 1) Normlize x/max(x)
# -- -- -- (OPTION 2) Standarize (x-mean(x))/sd(x)
# -- -- -- (OPTION 3) Robust Scale (x - median(x))/IQR
# -- -- Continue

# -- -- Conduct the hyperparameter optimization for all models (Genetic Algorithms with its own parameters)
# -- -- Select the fitness metric for the optimization
        (OPTION 1) AUC with train data
        (OPTION 2) AUC with test data
        (OPTION 3) mean of train and test AUC
        (OPTION 4) weighted-mean (80-20) of train and test AUC
        (OPTION 5) inv-weighted-mean (20-80) of train and test AUC

# -- -- Save the HoF with best N individuals
# -- -- Calculate model metrics for the entire Hall of Fame
# -- -- Calculate Model-inFold Performance Metric to find max and min in the fold: 
        (OPTION 1) AUC with train data
        (OPTION 2) AUC with test data
        (OPTION 3) mean of train and test AUC
        (OPTION 4) weighted-mean (80-20) of train and test AUC
        (OPTION 5) inv-weighted-mean (20-80) of train and test AUC

# -- -- Save the parameter set that produces the max, min value of the Choosen Performance Metric
# -- -- Save the number of occurrences of every parameter set (extract the modes)


# -- ---------------------------------------------------------------------- SYMBOLIC FEATURE ENGINEERING -- # 
# -- --------------------------------------------------------------------------------------------------- -- #

# -- Autoregressive features
# -- Hadamard features

# -- Genetic Programming for Symbolic Features
# -- -- iterative genetic parameters: Functions, Population, Generations, Tournament, HoF, output features
# -- -- Heuristics 
# -- -- -- Fitness for feature selection: Largest pearson coefficient between
		   symbolic continuous variables & target binary variable
# -- -- -- Feature parsimony

# -- ----------------------------------------------------------------------------------- MODEL DIVERSITY -- # 
# -- --------------------------------------------------------------------------------------------------- -- #

# -- Basic - Logistic Regression with regularization
# -- Statistical Learning - Support Vector Machines with L1 regularization
# -- Machine Learning - Aritificial Neural Network - Multi Layer Pereceptron
# -- Tree-based-ensemble method - RandomForest

# ------------------------------------------------------------------------------------ SUBJECTS BY CLASS -- #
# ------------------------------------------------------------------------------------------- ---------- -- #

- Machine Learning
- - (Done) Used K-fold Cross-Validation technique as a basis and proposed some variations in order to use
	it in financial time series data, this in line with what is included in hastie & tibshirani 
	Elements of Statistical Learning.

- - (Pending) Gradient descent vs Genetic Algorithm as methods of learning for the models
    SAGA: A Fast Incremental Gradient Method WithSupport for Non-Strongly Convex CompositeObjectives.
    SGD: Stochastic Gradient Descent.
    Loss functions for binary classification models ??

- - (Extra) Regularization factors L1, and L2 combined in Elastic Net

- Time Series
- - (Done) Base properties of time series data
- - (Pending) AIC and BIC criterias for model selection

- Convex Optimization
- - (Pending) Convexity of loss function utilized for training the models
- - (Done) Logistic Regression model
- - (Done) Support Vector Machines model
- - (Done) Regularization factors L1, and L2 combined in Elastic Net

- Predictive Modeling
- - (pending) Data profiling
- - (pending) RandomForest model use for binary classification

- Analysis and Design of Algorithms
- - (Pending) Complexity analysis of T-Fold technique
- - (Pending) Complexity analysis of predictive models
- - (Pending) Calibration technique design and complexity analysis
- - (Pending) Genetic Algorithms 

- Previously
- - (Done) Multilayer Pereceptron model

# ------------------------------------------------------------------------------------------- CHANGE LOG -- #
# ------------------------------------------------------------------------------------------- ---------- -- #

# -- 10.02.2021

- create a new document.py file with all the codes necessary to produce the elements that will be
  added to the thesis document.

- T-Fold process completed

- Enhacement: refactor project structure to support parallelization
- Addition: Log registration with every worker in the paralelization

- mapped all variations of factors to run the general experiment 
- - different types of data pre-processing (Normalize, Standarize, Robust Standarization)
- - data pre-processing order (pre/post features)

- - fitness metric as cost function (optimization process)
	ACC: (train, test, simple, weighted, inv-weighted)
	AUC: (simple, weighted, inv-weighted)
	LOGLOSS: (simple, weighted, inv-weighted)

- - fitness metric as ranking function (selection of cases max, min)
	ACC: (train, test, simple, weighted, inv-weighted)
	AUC: (simple, weighted, inv-weighted)
	LOGLOSS: (simple, weighted, inv-weighted)

- Addition: Asyncronous parallelization capabilities for several functions
- Enhacement: Aesthetic Logs and invidiual files for worker-log during parallelization
- Addition: pickle_rick data saving method for individual file during parallelization

# -- 11.02.2021

- Addition: data_profile function for OHLC and timeseries data profiling
- Addition: data profile for target variable (balance of classes)
- Addition: data profile for feature variables (descriptive statistics)
- Addition: table Correlation between features and features vs target variable

# -- 12.02.2021 

- Enhacement: Variations of AUC, LogLoss, ACC to use as cost functions and ranking function
- Enhacement: search for min, max, mode cases according to selected cost function
- Enhacement: ROC plot to support Multiple ROC values of the evaluated HoF
- Addition: table for multi modal cases

- Enhacement: Global evaluation function for the whole HoF 
- Fix: gray candles (windows without prediction) and vertical line traintest ohlc class
- Results: Execute code with several features to have wider results to analize.

# -- 13.02.2021

- Optimization: add to model_metrics the other sofisticated metrics already calculated
- Optimization: refactor and simplify code in genetic_algo_evaluate 
- Enhacement: add inner-split option of iterations (choose inner test split of data)
- Addition: met_cases params and metric data of the min and max cases
- Enhacement: Refactor project in order to work with no train-test split in inner data sets of the t-folds

# -- 14.02.2021
- Fix: model fit and predict separation in model evaluation
- Enhacement: Train&Test option for plots

# -- 17.02.2021
- Enhacement: Install GPU capabilities in T490

# -- 18.02.2021
- Enhacement: Migrate from sklearn to keras (basic tests)
- Modification: Hide tensorflow console messages

# -- 19.02.2021
- Fix: use pickle to save tf.keras model 

- (goal) Fix: global evaluation test for tf.keras models (with model.predict())


- (goal) Enhacement: Expand hyperparameter to search for ann-mlp model 
-                      (1) list of additional elements for model, (2) include in genetic_algo_opt, (3) testing

# ---------------------------------------------------------------------------------------------- BACKLOG -- # 
# ---------------------------------------------------------------------------------------------- ------- -- #

# -- NECESSARY

- (pending) Implement embargo criteria for t-fold variation
- (pending) Change from sklearn to keras for ANN-MLP
- (pending) Expand hyperparameters to search for ANN-MLP

- (pending) Refactor tf_model_metrics and sk_model_metrics to not use train/test condition (just any data)

- (pending) add RandomForest classification model with scikit learn

- (pending) final prediction criterias (best of bests, )

- (pending) Refactor code for timeseries data of metric evolution g_timeseries_auc

- (pending) reduce time elapsed by global evaluation function

- (pending) look for repeated or not used data that is beign saved, pickle files are getting heavier

- (pending) function for average or AIC/BIC for parsimony analysis of symbolic features in fold

- (pending) visual profile: boxplot matrix with outliers for feature variables
- (pending) visual profile: histograms for feature variables
- (pending) visual profile: Correlation heatmap for feature variables
- (pending) visual profile: ROC curves of all HoF in the fold


- (pending) translate every comment to english
- (pending) translate every variable name to english

- (pending) (paper) design hypothesis based experiments 
- (pending) (code) register the modifications in the code necessary for each experiment

# -- GOOD TO HAVE

- (pending) guide to multi-gpu & distributed training.

***************************************************************************************** UNORGANIZED NOTES 
***********************************************************************************************************

# -- NOTES FOR FINAL PRESENTATION

- Para que sirve todo esto para mejorar el desempeño de modelos respecto a un procedimiento clasico?

- como justificar el inv-weighted y proporciones

- Que tan viable es que, al utilizar los parametros del mlp se puede replicar despues. 
- lo bueno es que guardo el objeto que tiene el modelo (por las condiciones inciiales para el)

- Para el caso de Ensamble, como randomforest, utilizar todos los casos en lugar de hacer los 3 mejores. 

# -- For each model show
# -- -- Objective function
# -- -- Cost function 
# -- -- Learning/Optimizing algorithm (Genetic algorithms because categorical data)

# -- -- DATA ANALYSIS
# -- -- -- Amount/dates of data
# -- -- -- Balance of the clases

# -- -- MODEL ANALYSIS
# -- -- -- change in accuracy
# -- -- -- change in auc
# -- -- -- change in parameters

# -- PARAMETER ESTABILITY
# -- -- for every model in every T-Fold evaluate the best and worst of the HoF of the fold
# -- -- display timeseries parameters dataframe (parameters of all bests/worsts of all the folds)
# -- -- display timeseries metrics plots (of all bests/worsts of all the folds)
# -- -- -- AUC, ACC
# -- -- display all the ROC curves and average ROC curve plot for every model

# -- Possible questions to answer:
# -- -- is this method useful to find a parameter set that does not change a lot in time ?
# -- -- is this method useful to have a stable generalization error of the model ?
# -- -- does this method shows that a linear combination of non-linear features performs well
        in financial timeseries forecasting ?
# -- -- what role plays the feature complexity in this method ?
# -- -- What is the time complexity of this method ? 
# -- -- What is the memory complexity of this method ? 

# -- ANN-MLP
# -- -- HYPERPARAMETERS

# -- -- -- hidden_layer_sizes: The ith element represents the number of neurons in the ith hidden layer.
# -- -- -- alpha: L2 penalty (regularization term) parameter.
# -- -- -- activation: Activation function for the hidden layer.
# -- -- -- learning_rate_init: The initial learning rate used. It controls the step-size in updating the weights.

# cross analysis (Winning Fold Vs Global Test)
# -- outliers vs regularization
# -- symmetry vs regularization
# -- correlation vs regularization
# -- parsimony vs outliers
# -- parsimony vs symmetry

# model response to features from Fold to Global
# -- Regularization effects in logistic regression
# -- kernel in SVM
# -- training time in ANN-MLP
